---
layout: post
title: Would AI Development Be Stopped due to Human Fear?
date: 2016-10-03
comments: true
category: [Essay]
tags: [AI]

---

> This time, the AI seems to be quite a threat to human's survival.

The point I talk about in this article is just some thought that struck me this morning when I was taking a shower. I think it makes some sense but I haven't found time to set a solid foundation for it. Please feel free to give me comments, some sources of proof, or reasons of objection.

The point that hit me was: **Would artificial intelligence development be stopped forcefully because we humans are so concerned of losing control over it?**

The series of movies [_The Terminator_](https://en.wikipedia.org/wiki/The_Terminator) have shown what a horrible world the survived human would be living in after we lost the control over AI, but, if I remember correctly, they seem not to show how we lost the control.

The movie [_I, Robot_](https://en.wikipedia.org/wiki/I,_Robot_(film)) actually tells one possibility how we humans may lose the control of the AI: the AI simply evolves to an unexpected direction that their creators, we humans, fail to anticipate.

I happened to listen to a recent TED talk given by Sam Harris [_Can we build AI without losing control over it?_](http://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it). I like some of the points that the speaker made. For example, he used the relationship between humans and ants to suggest a possible relationship between machines with super-intelligence and humans. He said we humans usually don't want to hurt ants and, in fact, we may take pains to step over them in order not to harm them. However, as the speaker continued to say, "...whenever their presence seriously conflicts with one of our goals, let's say when constructing a building like this one, we annihilate them without a qualm. The concern is that we will one day build machines that, whether they're conscious or not, could treat us with similar disregard." The same thing may happen between machines and humans. In order to prevent this from happening, we humans must guarantee the machines' goals are always aligned to our goals. However, as the speaker suggests, this would be very difficult.

I personally agree with this point. I think it's impossible for human beings to make a perfect design of AI so it won't destroy us, because the design is made by humans, and humans' mind is not flawless. Just see how many system updates you get for your Windows, Ubuntu or Mac OS. All of the mentioned operating systems are developed by a group of very smart people.

This TED talk also reminds me of a video I saw a few years ago which shows how quickly the machine can develop an acceptable solution. See it here: [Natural Motion- Biped Learning to Walk Using Evolved Neural Nets](https://www.youtube.com/watch?v=JFJkpVWTQVM). In terms of speed, we humans cannot compete with machines at all.

Although people might use the industrial revolution in England as an example to argue that the development of technology is inevitable and won't be stopped simply because some people, or part of the human community, object to them, I would say AI might be an exception **because the machines that were invented in the industrial revolution were still in the total control of human, but the machines run by AI are not guaranteed to be. They will be run by some intelligence that learns, thinks, acts and thus evolves much faster than humans do, and that intelligence would probably have access to all the computers that connect to the Internet, which could further boost its rate of learning.**

As a result, we humans might form some sort of global committee to evaluate whether AI is becoming increasingly dangerous that might threaten our survival. If it is, this committee may issue a command to stop the AI development whatsoever.

However, as what typically happens in a movie, there will always be some people that want to either control the whole world or make great benefit from the black market of technology. These guys will completely ignore the prohibition and continue to develop that secretly. Eventually, the [skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator)) would be invented and terminated all the human.
