---
layout: draft
title: Would AI Development Be Stopped due to Human Fear?
date: 2016-10-03
comments: true
category: [AI]
tags: [AI]

---

> This time, the AI seems to be quite a threat to human's survival.

The point I talk about in this article is just some thought that struck me this morning when I was taking a shower. I think it makes some sense but I haven't found time to set a solid foundation for it. Please feel free to give me comments, some sources of proof, or reasons of objection.

The point that hit me was: **Would artificial intelligence development be stopped forcefully because we humans are so concerned of losing control over it?**

The series of movies [_The Terminator_](https://en.wikipedia.org/wiki/The_Terminator) have shown what a horrible world the survived human would be living in after we lost the control over AI, but, if I remember correctly, they seem not to show how we lost the control.

The movie [_I, Robot_](https://en.wikipedia.org/wiki/I,_Robot_(film)) actually tells one possibility how we humans may lose the control of the AI: the AI simply evolves to an unexpected direction that their creators, we humans, fail to anticipate.

I happened to listen to a recent TED talk given by Sam Harris [_Can we build AI without losing control over it?_](http://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it). (TODO)

Although people might use the industrial revolution in England as an example to argue that the development of technology is inevitable and won't be stopped simply because some people, or part of the human community, object to them, I would say AI might be an exception **because the machines that were invented in the industrial revolution were still in the total control of human, but the machines run by AI are not guaranteed to be. They will be run by some intelligence that learns, thinks, acts and thus evolves much faster than humans do, and that intelligence would probably have access to all the computers that connect to the Internet, which could further boost its rate of learning.**

As a result, we humans might form some sort of global committee to evaluate whether AI is becoming increasingly dangerous that might threaten our survival. If it is, this committee may issue a command to stop the AI development whatsoever.

However, as what typically happens in a movie, there will always be some people that want to either control the whole world or make great benefit from the black market of technology. These guys will completely ignore the prohibition and continue to develop that secretly. Eventually, the [skynet](https://en.wikipedia.org/wiki/Skynet_(Terminator)) would be invented and terminated all the human.

Main points:
* In the future, would AI technology be stopped due to human fear?
* Why stopped? Human realizes they may not have the total control of the AI.
* Earlier in the human history: People have the control.
* Ref: [Sam Harris: Can we build AI without losing control over it?](http://www.ted.com/talks/sam_harris_can_we_build_ai_without_losing_control_over_it)

TODO:
* Listen to the TED talk.
* Learn about the word *human*.
* Find the video that shows how quickly AI can evolve.
